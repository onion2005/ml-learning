{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efac4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created S3 bucket: ml-learning-sagemaker-20250922\n",
      "‚úÖ Uploaded model to s3://ml-learning-sagemaker-20250922/models/iris_classifier_20250922_141057.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create new notebook: notebooks/02_sagemaker_deployment.ipynb\n",
    "# Cell 1: Upload yesterday's model to S3\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Create S3 bucket for SageMaker (if you didn't yesterday)\n",
    "bucket_name = f\"ml-learning-sagemaker-{datetime.now().strftime('%Y%m%d')}\"\n",
    "region = 'ap-southeast-2'\n",
    "\n",
    "try:\n",
    "    # Create bucket\n",
    "    s3.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "    )\n",
    "    print(f\"‚úÖ Created S3 bucket: {bucket_name}\")\n",
    "except Exception as e:\n",
    "    if 'BucketAlreadyExists' in str(e):\n",
    "        print(f\"üìÅ Bucket {bucket_name} already exists\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Error creating bucket: {e}\")\n",
    "\n",
    "# Find your saved model from yesterday\n",
    "model_files = [f for f in os.listdir('../models') if f.endswith('.pkl')]\n",
    "if not model_files:\n",
    "    print(\"‚ùå No model files found. Please complete Day 1 first.\")\n",
    "else:\n",
    "    latest_model = max(model_files, key=lambda f: os.path.getctime(f'../models/{f}'))\n",
    "    model_path = f'../models/{latest_model}'\n",
    "    \n",
    "    # Upload model to S3\n",
    "    s3_model_key = f'models/{latest_model}'\n",
    "    s3.upload_file(model_path, bucket_name, s3_model_key)\n",
    "    \n",
    "    # Upload metadata too\n",
    "    metadata_file = latest_model.replace('.pkl', '_metadata.json')\n",
    "    metadata_path = f'../models/{metadata_file}'\n",
    "    if os.path.exists(metadata_path):\n",
    "        s3_metadata_key = f'models/{metadata_file}'\n",
    "        s3.upload_file(metadata_path, bucket_name, s3_metadata_key)\n",
    "    \n",
    "    print(f\"‚úÖ Uploaded model to s3://{bucket_name}/{s3_model_key}\")\n",
    "    \n",
    "    # Save these for later use\n",
    "    with open('../config.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'bucket_name': bucket_name,\n",
    "            'model_s3_key': s3_model_key,\n",
    "            'region': region\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae74d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Using existing role: arn:aws:iam::409633134924:role/SageMakerExecutionRole-MLLearning\n",
      "üéØ SageMaker setup complete!\n",
      "   Bucket: ml-learning-sagemaker-20250922\n",
      "   Role: arn:aws:iam::409633134924:role/SageMakerExecutionRole-MLLearning\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Set up SageMaker IAM role\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "role_name = 'SageMakerExecutionRole-MLLearning'\n",
    "\n",
    "# Define the trust policy for SageMaker\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define permissions policy\n",
    "permissions_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{bucket_name}\",\n",
    "                f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogGroup\",\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "                \"cloudwatch:PutMetricData\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Create the role\n",
    "    role_response = iam.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "        Description='SageMaker execution role for ML learning'\n",
    "    )\n",
    "    role_arn = role_response['Role']['Arn']\n",
    "    print(f\"‚úÖ Created role: {role_arn}\")\n",
    "    \n",
    "    # Create and attach policy\n",
    "    policy_response = iam.create_policy(\n",
    "        PolicyName='SageMakerMLLearningPolicy',\n",
    "        PolicyDocument=json.dumps(permissions_policy)\n",
    "    )\n",
    "    \n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=policy_response['Policy']['Arn']\n",
    "    )\n",
    "    print(\"‚úÖ Attached permissions policy\")\n",
    "    \n",
    "except Exception as e:\n",
    "    if 'EntityAlreadyExists' in str(e):\n",
    "        # Role already exists, get its ARN\n",
    "        role_response = iam.get_role(RoleName=role_name)\n",
    "        role_arn = role_response['Role']['Arn']\n",
    "        print(f\"üìÅ Using existing role: {role_arn}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Error creating role: {e}\")\n",
    "        # Fallback to using SageMaker's default service role\n",
    "        role_arn = f\"arn:aws:iam::{boto3.client('sts').get_caller_identity()['Account']}:role/service-role/AmazonSageMaker-ExecutionRole-*\"\n",
    "\n",
    "# Save role ARN for later\n",
    "config = json.load(open('../config.json'))\n",
    "config['role_arn'] = role_arn\n",
    "with open('../config.json', 'w') as f:\n",
    "    json.dump(config, f)\n",
    "    \n",
    "print(f\"üéØ SageMaker setup complete!\")\n",
    "print(f\"   Bucket: {bucket_name}\")\n",
    "print(f\"   Role: {role_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3fb1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/jean/Library/Application Support/sagemaker/config.yaml\n",
      "üìã SageMaker Session Information:\n",
      "   Default bucket: ml-learning-sagemaker-20250922\n",
      "   Region: ap-southeast-2\n",
      "   Role ARN: arn:aws:iam::409633134924:role/SageMakerExecutionRole-MLLearning\n",
      "‚úÖ SageMaker access confirmed\n",
      "   Found 0 existing models in account\n",
      "\n",
      "üöÄ Ready to deploy your first model to SageMaker!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize SageMaker\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# Load configuration\n",
    "config = json.load(open('../config.json'))\n",
    "\n",
    "# Create SageMaker session\n",
    "sagemaker_session = sagemaker.Session(default_bucket=config['bucket_name'])\n",
    "\n",
    "print(f\"üìã SageMaker Session Information:\")\n",
    "print(f\"   Default bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"   Region: {sagemaker_session.boto_region_name}\")\n",
    "print(f\"   Role ARN: {config['role_arn']}\")\n",
    "\n",
    "# Test SageMaker access\n",
    "try:\n",
    "    # List any existing models\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    models = sm_client.list_models(MaxResults=5)\n",
    "    print(f\"‚úÖ SageMaker access confirmed\")\n",
    "    print(f\"   Found {len(models['Models'])} existing models in account\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è SageMaker access issue: {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to deploy your first model to SageMaker!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb34ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created SageMaker inference script\n",
      "üìÑ Script includes:\n",
      "   - model_fn: Loads your trained model\n",
      "   - input_fn: Parses incoming requests\n",
      "   - predict_fn: Makes predictions\n",
      "   - output_fn: Formats responses\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create model inference script\n",
    "\n",
    "# SageMaker requires specific entry point scripts\n",
    "# Create the script that SageMaker will use to load and run your model\n",
    "\n",
    "inference_script = '''\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the model from the model_dir. This is called once per worker.\"\"\"\n",
    "    import os\n",
    "    model_path = os.path.join(model_dir, 'iris_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Parse input data for inference.\"\"\"\n",
    "    if request_content_type == 'application/json':\n",
    "        # Parse JSON input\n",
    "        input_data = json.loads(request_body)\n",
    "        \n",
    "        # Handle different input formats\n",
    "        if isinstance(input_data, list):\n",
    "            # Direct list of features: [5.1, 3.5, 1.4, 0.2]\n",
    "            return np.array([input_data])\n",
    "        elif isinstance(input_data, dict):\n",
    "            if 'instances' in input_data:\n",
    "                # Batch format: {\"instances\": [[5.1, 3.5, 1.4, 0.2], [...]]}\n",
    "                return np.array(input_data['instances'])\n",
    "            else:\n",
    "                # Named features: {\"sepal_length\": 5.1, \"sepal_width\": 3.5, ...}\n",
    "                features = [\n",
    "                    input_data.get('sepal_length', 0),\n",
    "                    input_data.get('sepal_width', 0),\n",
    "                    input_data.get('petal_length', 0),\n",
    "                    input_data.get('petal_width', 0)\n",
    "                ]\n",
    "                return np.array([features])\n",
    "    \n",
    "    elif request_content_type == 'text/csv':\n",
    "        # Parse CSV input\n",
    "        df = pd.read_csv(StringIO(request_body), header=None)\n",
    "        return df.values\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Make prediction using the loaded model.\"\"\"\n",
    "    predictions = model.predict(input_data)\n",
    "    probabilities = model.predict_proba(input_data)\n",
    "    \n",
    "    # Return both prediction and confidence\n",
    "    results = []\n",
    "    class_names = ['setosa', 'versicolor', 'virginica']\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        results.append({\n",
    "            'predicted_class': class_names[pred],\n",
    "            'predicted_class_id': int(pred),\n",
    "            'confidence': float(max(probabilities[i])),\n",
    "            'probabilities': {\n",
    "                class_names[j]: float(probabilities[i][j]) \n",
    "                for j in range(len(class_names))\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"Format the prediction output.\"\"\"\n",
    "    if content_type == 'application/json':\n",
    "        return json.dumps(prediction), content_type\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "'''\n",
    "\n",
    "# Save the inference script\n",
    "os.makedirs('../sagemaker_code', exist_ok=True)\n",
    "with open('../sagemaker_code/inference.py', 'w') as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "print(\"‚úÖ Created SageMaker inference script\")\n",
    "print(\"üìÑ Script includes:\")\n",
    "print(\"   - model_fn: Loads your trained model\")\n",
    "print(\"   - input_fn: Parses incoming requests\")\n",
    "print(\"   - predict_fn: Makes predictions\")\n",
    "print(\"   - output_fn: Formats responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b9e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating iris dataset...\n",
      "‚úÖ Created data/iris_processed.csv\n",
      "üìÅ Shape: (150, 6)\n",
      "\n",
      "First few rows:\n",
      "   sepal_length  sepal_width  petal_length  petal_width  target species\n",
      "0           5.1          3.5           1.4          0.2       0  setosa\n",
      "1           4.9          3.0           1.4          0.2       0  setosa\n",
      "2           4.7          3.2           1.3          0.2       0  setosa\n",
      "3           4.6          3.1           1.5          0.2       0  setosa\n",
      "4           5.0          3.6           1.4          0.2       0  setosa\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell to create iris_processed.csv\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"üìä Creating iris dataset...\")\n",
    "\n",
    "# Load iris dataset from sklearn\n",
    "iris = load_iris()\n",
    "\n",
    "# Create DataFrame with features\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Rename columns to simpler names\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "# Add target and species names\n",
    "df['target'] = iris.target\n",
    "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "df.to_csv('data/iris_processed.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Created data/iris_processed.csv\")\n",
    "print(f\"üìÅ Shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7c7e0",
   "metadata": {},
   "outputs": [],
   "source": "# Combined training and deployment in SageMaker\nfrom sagemaker.sklearn.estimator import SKLearn\nfrom datetime import datetime\nimport json\nimport numpy as np\nimport pandas as pd\nimport boto3\nimport os\n\n# Load configuration\nconfig = json.load(open('../config.json'))\n\nprint(\"üöÄ Training and deploying directly in SageMaker...\")\n\n# Prepare training data in S3\ntrain_path = f\"s3://{config['bucket_name']}/data/train/iris.csv\"\n\n# Upload your training data if not already there\ndf = pd.read_csv('../data/iris_processed.csv')\ndf.to_csv('/tmp/iris.csv', index=False)\ns3 = boto3.client('s3')\ns3.upload_file('/tmp/iris.csv', config['bucket_name'], 'data/train/iris.csv')\n\n# Create training script\nos.makedirs('../source', exist_ok=True)\nwith open('../source/train.py', 'w') as f:\n    f.write('''\nimport pandas as pd\nimport joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nimport os\n\nif __name__ == '__main__':\n    # Read data\n    input_path = '/opt/ml/input/data/train'\n    df = pd.read_csv(os.path.join(input_path, 'iris.csv'))\n    \n    # Prepare features\n    X = df.drop(['target'], axis=1, errors='ignore')\n    y = df['target']\n    \n    # Train\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n    model.fit(X_train, y_train)\n    \n    # Save model\n    model_path = '/opt/ml/model'\n    joblib.dump(model, os.path.join(model_path, 'model.joblib'))\n''')\n\n# Train in SageMaker\nsklearn_estimator = SKLearn(\n    entry_point='train.py',\n    source_dir='../source',\n    framework_version='1.2-1',\n    instance_type='ml.m5.xlarge',\n    role=config['role_arn'],\n    sagemaker_session=sagemaker_session\n)\n\nsklearn_estimator.fit({'train': train_path})\n\n# Deploy\nendpoint_name = f'iris-classifier-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\npredictor = sklearn_estimator.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.large',\n    endpoint_name=endpoint_name\n)\n\nprint(f\"‚úÖ Endpoint deployed: {endpoint_name}\")\n\n# Save config\nconfig['endpoint_name'] = endpoint_name\nwith open('../config.json', 'w') as f:\n    json.dump(config, f)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67338679",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Test the deployed endpoint\nimport numpy as np\nimport joblib\n\n# Test data - different iris flower measurements\ntest_cases = [\n    {\n        \"name\": \"Typical Setosa\",\n        \"features\": [5.1, 3.5, 1.4, 0.2],\n        \"expected\": \"setosa\"\n    },\n    {\n        \"name\": \"Typical Versicolor\", \n        \"features\": [6.0, 2.8, 4.5, 1.3],\n        \"expected\": \"versicolor\"\n    },\n    {\n        \"name\": \"Typical Virginica\",\n        \"features\": [7.2, 3.0, 5.8, 2.3],\n        \"expected\": \"virginica\"\n    },\n    {\n        \"name\": \"Edge case\",\n        \"features\": [5.8, 2.7, 4.1, 1.0],\n        \"expected\": \"versicolor or virginica\"\n    }\n]\n\nprint(\"üß™ Testing deployed model with various inputs...\")\nprint(\"=\" * 60)\n\nif 'endpoint_name' in config:\n    for test_case in test_cases:\n        try:\n            # Make prediction\n            result = predictor.predict(test_case[\"features\"])\n            \n            print(f\"\\nüå∏ Test: {test_case['name']}\")\n            print(f\"   Input: {test_case['features']}\")\n            print(f\"   Expected: {test_case['expected']}\")\n            print(f\"   Predicted: {result[0]['predicted_class']}\")\n            print(f\"   Confidence: {result[0]['confidence']:.2%}\")\n            \n            # Show all probabilities\n            print(\"   Probabilities:\")\n            for species, prob in result[0]['probabilities'].items():\n                print(f\"     {species}: {prob:.2%}\")\n                \n        except Exception as e:\n            print(f\"‚ùå Test failed: {e}\")\nelse:\n    print(\"‚ö†Ô∏è No endpoint available. Testing with local model instead...\")\n    # Fallback to local testing\n    # Find the latest model file\n    import os\n    import glob\n    model_files = glob.glob('../models/*.pkl')\n    if model_files:\n        latest_model = max(model_files, key=os.path.getctime)\n        local_model = joblib.load(latest_model)\n        class_names = ['setosa', 'versicolor', 'virginica']\n        \n        for test_case in test_cases:\n            features = np.array([test_case['features']])\n            prediction = local_model.predict(features)[0]\n            probabilities = local_model.predict_proba(features)[0]\n            \n            print(f\"\\nüå∏ Test: {test_case['name']}\")\n            print(f\"   Input: {test_case['features']}\")\n            print(f\"   Expected: {test_case['expected']}\")\n            print(f\"   Predicted: {class_names[prediction]}\")\n            print(f\"   Confidence: {max(probabilities):.2%}\")\n    else:\n        print(\"‚ùå No local model files found either.\")\n\nprint(\"\\n‚úÖ Model testing completed!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}